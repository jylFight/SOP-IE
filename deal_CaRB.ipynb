{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10865b5f-5de9-44bf-aa5f-9f9799325b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc7fb30-1d27-427d-8f9d-e774562d0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word(sent_list,temp_list):      #一个list里找另一个list的函数，主要是针对arg1和arg2的span\n",
    "    result=[]\n",
    "    temp_len=len(temp_list)\n",
    "    for i in range(len(sent_list)-temp_len):\n",
    "        if sent_list[i:i+temp_len]==temp_list:\n",
    "            result.append(list(range(i,i+temp_len)))      #本来是简单的append[i,i+temp_len]，但是为了方便后面的find_span，就改了\n",
    "            break\n",
    "    if result==[]:\n",
    "        result=[[]]\n",
    "    return result[0]\n",
    "\n",
    "def remove(a_list,a):                    #list.remove不好用，只能自己创建一个函数来去除多余的''\n",
    "    new_list=[]\n",
    "    for i in a_list:\n",
    "        if i==a:\n",
    "            continue\n",
    "        new_list.append(i)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eebf5d8-a1b0-4ef4-8d59-8011a700ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_span(sent_list,temp_list):                        #给定句子的token_list和arg的token_list然后进行递归匹配子块\n",
    "    result=find_word(sent_list,temp_list)\n",
    "    if result==[]:                                         #没匹配上，说明要么是两个词块拼一起，要么就是有句中不存在的词                  \n",
    "        if temp_list==[]:                                  #比如rel里只有is且is还不在句子里\n",
    "            return []\n",
    "        temp_result=[]\n",
    "        for i in range(0,2):\n",
    "            new_temp_list=temp_list[i:len(temp_list)-1+i]    #取小的子块儿\n",
    "            temp_result.append(find_span(sent_list,new_temp_list))                    #递归\n",
    "        result_len=[len(j) for j in temp_result]\n",
    "        position=result_len.index(max(result_len))\n",
    "        result=temp_result[position]\n",
    "    return result\n",
    "#测试完毕，终于搞定了，很NB！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ed2ef3-9de4-4f16-a53b-874bf570456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_tag(sent_list,tag):\n",
    "    new_sent=sent_list+['is','have','from']\n",
    "    a1,a2,rel=[],[],[]\n",
    "    for i in range(len(tag)):\n",
    "        if tag[i]==1 or tag[i]==2:\n",
    "            a1.append(sent_list[i])\n",
    "        if tag[i]==3 or tag[i]==4:\n",
    "            a2.append(sent_list[i])\n",
    "        if tag[i]==5:\n",
    "            rel.append(new_sent[i])\n",
    "    return ' '.join(a1),' '.join(a2),' '.join(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b5cef5-6ca3-4b95-816b-4600092367e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选一下三元组，保留arg2存在且不重复的三元组\n",
    "def filter1(gold_data):\n",
    "    temp=[]\n",
    "    for gold in gold_data:\n",
    "        data=gold.split('\\t')\n",
    "        if len(data)<4:\n",
    "            continue\n",
    "        if len(data)>4:\n",
    "            new_gold='\\t'.join(data[:4])+'\\n'\n",
    "            if new_gold not in temp:\n",
    "                temp.append(new_gold)\n",
    "        if len(data)==4 and gold not in temp and data[3]!='\\n':    #arg2即使没有可能还会是\\n\n",
    "            temp.append(gold)\n",
    "    print(len(temp),len(gold_data))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008c8ef4-08fa-44ac-9dc8-e53891263440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_carb(temp,train=False):\n",
    "    sent=temp[0].split('\\t')[0]\n",
    "    index,result,arg1_list,arg2_list,tags_list,arg1_str,arg2_str,rel_str=0,[],[],[],[],[],[],[]\n",
    "    n1,n2,n3=0,0,0\n",
    "    for temp_data in temp:\n",
    "        data=temp_data.split('\\t')      #data[0]是句子，data[1]是rel，data[2]是arg1，data[3]是arg2\n",
    "        if not data[0]==sent:\n",
    "            if arg1_list!=[] and arg2_list!=[] and tags_list!=[]:\n",
    "                if train:               #train实在太多了，写入str的话会非常麻烦！\n",
    "                    feature={'sent':new_sent_list,'a1_tags':arg1_list,'a2_tags':arg2_list,'sent_id':index,'tags':tags_list}\n",
    "                else:\n",
    "                    feature={'sent':new_sent_list,'a1_tags':arg1_list,'a2_tags':arg2_list,'sent_id':index,'tags':tags_list,\n",
    "                        'a1':arg1_str,'a2':arg2_str,'rel':rel_str}\n",
    "                result.append(feature)\n",
    "            sent=data[0]\n",
    "            index+=1\n",
    "            arg1_list,arg2_list,tags_list,arg1_str,arg2_str,rel_str=[],[],[],[],[],[]\n",
    "        \n",
    "        sent_list=data[0].split(' ')\n",
    "        new_sent_list=remove(sent_list,'')          #有的句子最后的字符是''，tokenizer处理不了\n",
    "        arg1=data[2].split(' ')\n",
    "        arg2=data[3][:-1].split(' ')                #'/n'算一个字符\n",
    "        rel=data[1].split(' ')\n",
    "        new_arg1=remove(arg1,'')\n",
    "        new_arg2=remove(arg2,'')\n",
    "        new_rel=remove(rel,'')                       #这个数据不太行，这里这个rel的处理还得研究，包括这个arg也是，就离谱\n",
    "        if len(new_arg1)>8 or len(new_arg2)>8 or len(new_rel)>8: #span长度过长，但一般carb会好很多\n",
    "            n1+=1\n",
    "            continue\n",
    "        \n",
    "        if train:                                    #主要是train数据太多，所以在arg这里就不做子块筛选了，只做原本的span筛选\n",
    "            arg1_tag=find_word(new_sent_list,new_arg1)\n",
    "            arg2_tag=find_word(new_sent_list,new_arg2)\n",
    "        else:\n",
    "            arg1_tag=find_span(new_sent_list,new_arg1)\n",
    "            arg2_tag=find_span(new_sent_list,new_arg2)\n",
    "        if arg1_tag==[] or arg2_tag==[]:                          #理论上如果用find_span,n2应该是0\n",
    "            n2+=1\n",
    "            continue\n",
    "        rel_tag=find_span(new_sent_list,new_rel)\n",
    "        #print(new_arg1,arg1_tag,new_arg2,arg2_tag)\n",
    " \n",
    "        tag=torch.zeros(len(new_sent_list)+3)\n",
    "        tag[arg1_tag[0]]=1\n",
    "        tag[arg1_tag[0]+1:arg1_tag[-1]+1]=2\n",
    "        tag[arg2_tag[0]]=3\n",
    "        tag[arg2_tag[0]+1:arg2_tag[-1]+1]=4\n",
    "        if rel_tag!=[]:\n",
    "            tag[rel_tag[0]:rel_tag[-1]+1]=5\n",
    "        else:\n",
    "            if 'is' in rel or 'was' in rel:                       #分别代表is,of,from三个词凭空出现在rel里\n",
    "                tag[-3]=5\n",
    "            if 'of' in rel:\n",
    "                tag[-2]=5\n",
    "            if 'from' in rel:\n",
    "                tag[-3]=5\n",
    "            if 5 not in tag:                                      #这些准备都做完了还是没有rel，那可以拜拜了\n",
    "                n3+=1\n",
    "                continue\n",
    "                \n",
    "        arg1_list.append(arg1_tag)\n",
    "        arg2_list.append(arg2_tag)\n",
    "        tags_list.append(tag.tolist())\n",
    "\n",
    "        if train:\n",
    "            continue\n",
    "        a1,a2,re=deal_tag(new_sent_list,tag)                          #根据处理后的tag来得到a1,a2和rel，为下一步清洗做铺垫，因为取子块会有相似数据\n",
    "        arg1_str.append(a1)\n",
    "        arg2_str.append(a2)\n",
    "        rel_str.append(re)\n",
    "        \n",
    "    print(n1,n2,n3,len(temp),len(result))\n",
    "    return result\n",
    "    #这个函数意思是在test里进行条件筛选，筛选是，arg1和arg2必须是连续的span，还有rel词如果多了隐藏词，只能是is,of,from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14bce307-abb7-46b8-abcb-0d65737ff39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2455 2548\n",
      "450 17 185 2455 598\n"
     ]
    }
   ],
   "source": [
    "with open('../openie6-master/carb/data/gold/dev.tsv','r') as f:\n",
    "    gold_data=f.readlines()\n",
    "temp=filter1(gold_data)\n",
    "new_data=deal_carb(temp)\n",
    "with open('datasets/CaRB/dev.json','w') as f:\n",
    "    json.dump(new_data,f)\n",
    "#完美！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fd4d31a-17e9-455f-8297-80243dbadc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../openie6-master/imojie/data/train/4cr_qpbo_extractions.tsv','r') as f:\n",
    "    temp_data=f.readlines()\n",
    "#这里不如把这个数据变成gold_data的形式来试试\n",
    "#print(len(temp_data),temp_data[5])\n",
    "#这里设置了粗暴的筛选，因为数据太多了，首先，span只要不挨着，就算了，然后长度不能大于8，rel还是加了is,from,have\n",
    "filter_data=[]\n",
    "for data in temp_data:\n",
    "    data1=data.replace('<arg1>','')\n",
    "    data2=data1.replace('</arg1> <rel>','|')\n",
    "    data3=data2.replace('</arg2>','')\n",
    "    data4=data3.replace('</rel> <arg2>','|')\n",
    "    new_data=data4.split('\\t')\n",
    "    #print(data,new_data)\n",
    "    arg1=new_data[1].split('|')[0][1:-1]\n",
    "    arg2=new_data[1].split('|')[2]\n",
    "    rel=new_data[1].split('|')[1]\n",
    "    temp_result=new_data[0]+'\\t'+rel+'\\t'+arg1+'\\t'+arg2+'\\n'\n",
    "    filter_data.append(temp_result)\n",
    "#主要是把数据变成carb的形式好实用下面的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d68b6c0-cd74-439b-9872-b9f3235a50ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83511 29330 9 215356 66196\n",
      "CPU times: user 5.28 s, sys: 200 ms, total: 5.48 s\n",
      "Wall time: 5.48 s\n"
     ]
    }
   ],
   "source": [
    "%time new_data=deal_carb(filter_data,True)    #只剩下10W数据哈哈哈哈哈哈或\n",
    "with open('datasets/CaRB/train.json','w') as f:    #好家伙，写数据写了2个小时！？397个G！？\n",
    "   json.dump(new_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3c9e0-a5ff-4feb-80be-dfa0abfd0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里设计一个相似度函数来筛选一些相似的数据，以tag为基准就可以，如果两个tag的相似度在多少以上就可以，这个可以下一步看，看看具体能筛选多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858f1e3c-f2be-4289-b5ee-172bc32fd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_simliar(tag1,tag2):\n",
    "    x=(tag1==tag2).float()\n",
    "    similiar=torch.sum(x)/len(tag1)\n",
    "    return similiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0e147d-c51e-4ded-a86e-e8538284a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delettag(tag):   \n",
    "    result=[]\n",
    "    for i in range(len(tag)-1):\n",
    "        for j in range(len(tag[i+1:])):\n",
    "            new_j=j+i+1\n",
    "            simliar=tag_simliar(tag[i],tag[new_j])     #比较任意两个tag的相似性\n",
    "            if simliar>0.9:                                  \n",
    "                tag1_len=torch.sum((tag[i]>0).float())\n",
    "                tag2_len=torch.sum((tag[new_j]>0).float())\n",
    "                if tag1_len<tag2_len and i not in result: \n",
    "                    result.append(i)\n",
    "                if not tag1_len<tag2_len and new_j not in result:\n",
    "                    result.append(new_j)\n",
    "    return result\n",
    "#返回要删除的句子的序号，可以试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492ec92a-c07f-4e11-be98-a20cbdf4f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_elements(lista,index_list):\n",
    "    result=[]\n",
    "    for i,item in enumerate(lista):\n",
    "        if i not in index_list:\n",
    "            result.append(item)\n",
    "    return result\n",
    "#lista=['a','b','c','d','e','a','a']\n",
    "#listb=[1,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71a9d149-20b2-47e3-ba90-3c57102707c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new(tempdata,deletlist,train=False):\n",
    "    sent=tempdata['sent']\n",
    "    sent_id=tempdata['sent_id']\n",
    "    new_a1=remove_elements(tempdata['a1_tags'],deletlist)\n",
    "    new_a2=remove_elements(tempdata['a2_tags'],deletlist)\n",
    "    new_tag=remove_elements(tempdata['tags'],deletlist)\n",
    "    if train:\n",
    "        feature={'sent':sent,'a1_tags':new_a1,'a2_tags':new_a2,'sent_id':sent_id,'tags':new_tag}\n",
    "    else:\n",
    "        feature={'sent':sent,'a1_tags':new_a1,'a2_tags':new_a2,'sent_id':sent_id,'tags':new_tag,\n",
    "                'a1':tempdata['a1'],'a2':tempdata['a2'],'rel':tempdata['rel']}\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59aa8688-ea95-41ba-9071-e55911158472",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/CaRB/train.json','r') as f:\n",
    "    test_data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d8bd064-6644-4140-be01-e30e1b2d4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2390\n"
     ]
    }
   ],
   "source": [
    "#这里就这么简单粗暴的删除一下吧，然后看看效果，先存个新train、dev、test\n",
    "new_data,test,delete_num=[],[],0\n",
    "for data in test_data:\n",
    "    tag=torch.tensor(data['tags'])\n",
    "    test.append(delettag(tag))\n",
    "#test里是要删除的tag的序列，有可能为空\n",
    "for i in test:\n",
    "    if not i==[]:\n",
    "        delete_num+=len(i)\n",
    "print(delete_num)\n",
    "for i in range(len(test)):\n",
    "    if test[i]==[]:\n",
    "        new_data.append(test_data[i])\n",
    "    else:\n",
    "        new_feature=get_new(test_data[i],test[i],True)\n",
    "        new_data.append(new_feature)\n",
    "with open('datasets/CaRB/train_no_similiar.json','w') as f:\n",
    "    json.dump(new_data,f)\n",
    "#train数据里10W个数据，才2400个相似的，所以训练看来无所谓了，test和dev都是接近2000的数据，test里有225个,dev里面191个相似的，很有趣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "856b252a-d289-476a-ac83-4d4ff53de206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tsv(data,file_name):\n",
    "    with open(file_name,'w') as f:\n",
    "        for temp_data in data:\n",
    "            for i in range(len(temp_data['tags'])):\n",
    "                f.write(' '.join(temp_data['sent'])+'\\t'+temp_data['rel'][i]+'\\t'+temp_data['a1'][i]+'\\t'+temp_data['a2'][i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d73bb25-182a-4fe6-ad5b-0fc125237821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#把test和dev的处理后的数据写成tsv看看吧\n",
    "with open('datasets/CaRB/dev.json','r') as f:\n",
    "    dev_data=json.load(f)\n",
    "with open('datasets/CaRB/test.json','r') as f:\n",
    "    test_data=json.load(f)\n",
    "with open('datasets/CaRB/dev_no_similiar.json','r') as f:\n",
    "    new_dev_data=json.load(f)\n",
    "with open('datasets/CaRB/test_no_similiar.json','r') as f:\n",
    "    new_test_data=json.load(f)\n",
    "\n",
    "write_tsv(dev_data,'../openie6-master/MyORE_test/gold/dev_filter.tsv')\n",
    "write_tsv(test_data,'../openie6-master/MyORE_test/gold/test_filter.tsv')\n",
    "write_tsv(new_dev_data,'../openie6-master/MyORE_test/gold/dev_no_similiar.tsv')\n",
    "write_tsv(new_test_data,'../openie6-master/MyORE_test/gold/test_no_simililar.tsv')\n",
    "#原本的dev,2541,筛选后,1906,相似度筛选后，1712\n",
    "#原本的test,2691,筛选后,1892,相似度筛选后，1667\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c71998-f81d-4750-b0e7-e441cb3f1ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
